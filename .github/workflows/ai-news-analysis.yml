name: Patriots Protocol - Cost-Optimized Cyber Intelligence v4.0

on:
  schedule:
    # Reduced frequency: Run every 6 hours to minimize API costs
    - cron: '0 */6 * * *'
    # Daily cleanup at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      force_cleanup:
        description: 'Force data cleanup'
        required: false
        default: 'false'
      max_api_calls:
        description: 'Maximum API calls (default: 8)'
        required: false
        default: '8'
  push:
    branches: ["main"]
    paths-ignore:
      - 'archive/**'
      - '*.md'

permissions:
  contents: write
  pages: write
  id-token: write

concurrency:
  group: "patriots-protocol-cost-optimized-v4"
  cancel-in-progress: true  # Cancel previous runs to save resources

env:
  MAX_API_CALLS: ${{ github.event.inputs.max_api_calls || '8' }}
  DATA_RETENTION_DAYS: 6
  COST_LIMIT_USD: 0.05  # Maximum cost per run

jobs:
  # Data cleanup job - runs first to save space
  data-cleanup:
    runs-on: ubuntu-latest
    if: github.event.schedule == '0 2 * * *' || github.event.inputs.force_cleanup == 'true'
    steps:
      - name: Checkout Patriots Protocol
        uses: actions/checkout@v4

      - name: Setup Python for Cleanup
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Secure Data Cleanup
        run: |
          echo "🧹 PATRIOTS PROTOCOL v4.0 - Secure Data Cleanup Starting..."
          echo "📅 Cleanup Time: $(date -u +%Y-%m-%dT%H:%M:%S.%3NZ)"
          echo "🗂️  Data Retention: ${DATA_RETENTION_DAYS} days"
          
          # Create cleanup script
          cat > cleanup.py << 'EOF'
          import os
          import shutil
          from datetime import datetime, timedelta
          from pathlib import Path
          
          def secure_cleanup():
              retention_days = int(os.environ.get('DATA_RETENTION_DAYS', 6))
              cutoff_date = datetime.now() - timedelta(days=retention_days)
              
              total_files = 0
              total_size = 0
              
              # Directories to clean
              cleanup_dirs = ['./data', './logs', './backup', './archive']
              
              for dir_path in cleanup_dirs:
                  directory = Path(dir_path)
                  if directory.exists():
                      for file_path in directory.rglob('*'):
                          if file_path.is_file():
                              try:
                                  file_time = datetime.fromtimestamp(file_path.stat().st_mtime)
                                  if file_time < cutoff_date:
                                      file_size = file_path.stat().st_size
                                      
                                      # Secure deletion for sensitive files
                                      if file_path.suffix in ['.json', '.log', '.tmp']:
                                          # Overwrite before deletion
                                          with open(file_path, 'wb') as f:
                                              f.write(os.urandom(file_size))
                                      
                                      file_path.unlink()
                                      total_files += 1
                                      total_size += file_size
                                      
                              except Exception as e:
                                  print(f"Warning: Could not clean {file_path}: {e}")
              
              print(f"✅ Cleanup complete: {total_files} files, {total_size / (1024*1024):.2f} MB")
              return total_files, total_size
          
          if __name__ == "__main__":
              secure_cleanup()
          EOF
          
          python cleanup.py
          
          # Update git if files were cleaned
          git config --local user.email "patriots-cleanup@ai.cyber"
          git config --local user.name "Patriots Protocol Cleanup"
          
          if ! git diff --quiet; then
            git add -A
            git commit -m "🧹 Patriots Protocol v4.0: Automated secure data cleanup
            
            📅 Cleanup Time: $(date -u +'%Y-%m-%d %H:%M:%S UTC')
            🗂️  Retention Policy: ${DATA_RETENTION_DAYS} days
            🔒 Secure deletion applied"
            git push
          else
            echo "📋 No files to cleanup"
          fi

  # Cost-optimized intelligence gathering
  cost-optimized-intelligence:
    runs-on: ubuntu-latest
    if: github.event.schedule != '0 2 * * *'  # Skip during cleanup-only runs
    outputs:
      patriots_status: ${{ steps.ai_analysis.outputs.patriots_status }}
      threat_level: ${{ steps.ai_analysis.outputs.threat_level }}
      api_calls_used: ${{ steps.ai_analysis.outputs.api_calls_used }}
      cost_estimate: ${{ steps.ai_analysis.outputs.cost_estimate }}
      reports_processed: ${{ steps.ai_analysis.outputs.reports_processed }}
    steps:
      - name: Checkout Patriots Protocol v4.0
        uses: actions/checkout@v4

      - name: Setup Python for Cost-Optimized AI
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Create Secure Directory Structure
        run: |
          mkdir -p data archive logs
          chmod 750 data archive logs
          echo "🔒 Secure directories created with restricted permissions"

      - name: Install Optimized Dependencies
        run: |
          echo "📦 Installing cost-optimized dependencies..."
          pip install --upgrade pip
          pip install aiohttp feedparser asyncio openai python-dateutil
          echo "✅ Optimized dependencies installed"

      - name: Cost-Optimized Intelligence Analysis
        id: ai_analysis
        env:
          GITHUB_TOKEN: ${{ secrets.MODEL_TOKEN }}
          MODEL_TOKEN: ${{ secrets.MODEL_TOKEN }}
          MAX_API_CALLS: ${{ env.MAX_API_CALLS }}
          COST_LIMIT_USD: ${{ env.COST_LIMIT_USD }}
        run: |
          echo "🎖️  PATRIOTS PROTOCOL v4.0 - Cost-Optimized Cyber Intelligence Starting..."
          echo "📅 Mission Start: $(date -u +%Y-%m-%dT%H:%M:%S.%3NZ)"
          echo "💰 Cost Controls: Max API calls: ${MAX_API_CALLS}, Cost limit: $${COST_LIMIT_USD}"
          echo "🛡️  Security: Data retention ${DATA_RETENTION_DAYS} days"
          
          # Verify token
          if [ -z "$GITHUB_TOKEN" ]; then
            echo "❌ GITHUB_TOKEN not found"
            exit 1
          fi
          
          echo "✅ API token verified"
          echo "🤖 Model: openai/gpt-4.1-mini (cost-optimized)"
          echo "🔄 Executing cost-optimized analysis..."
          
          # Run cost-optimized analysis
          python patriots_ai_intel.py 2>&1 | tee logs/cost_optimized_analysis_$(date +%Y%m%d_%H%M%S).log
          
          # Extract cost metrics
          if [ -f ./data/news-analysis.json ]; then
            echo "✅ Cost-optimized intelligence data generated"
            
            python3 -c "
          import json
          import sys
          import os
          
          try:
              with open('./data/news-analysis.json', 'r') as f:
                  data = json.load(f)
              
              metrics = data.get('metrics', {})
              cost_info = data.get('cost_optimization', {})
              
              # Extract cost and usage metrics
              patriots_status = metrics.get('patriots_protocol_status', 'OPERATIONAL')
              threat_level = metrics.get('threat_level', 'LOW')
              api_calls_used = cost_info.get('api_calls_used', 0)
              cost_estimate = cost_info.get('estimated_cost', 0.0)
              reports_processed = metrics.get('total_articles', 0)
              
              # Cost efficiency report
              print(f'🎖️  Patriots Protocol v4.0 Cost-Optimized Report:')
              print(f'   💰 API Calls Used: {api_calls_used}/{cost_info.get(\"api_calls_limit\", 8)}')
              print(f'   💰 Estimated Cost: ${cost_estimate:.4f}')
              print(f'   📊 Reports Generated: {reports_processed}')
              print(f'   🎯 Threat Level: {threat_level}')
              print(f'   🧹 Files Cleaned: {cost_info.get(\"cleanup_stats\", {}).get(\"files_cleaned\", 0)}')
              print(f'   💾 Space Saved: {cost_info.get(\"cleanup_stats\", {}).get(\"space_saved_mb\", 0):.2f} MB')
              
              # Check cost limits
              cost_limit = float(os.environ.get('COST_LIMIT_USD', 0.05))
              if cost_estimate > cost_limit:
                  print(f'⚠️  Cost limit exceeded: ${cost_estimate:.4f} > ${cost_limit:.4f}')
                  sys.exit(1)
              
              # Set outputs
              with open(os.environ['GITHUB_OUTPUT'], 'a') as gh_output:
                  gh_output.write(f'patriots_status={patriots_status}\\n')
                  gh_output.write(f'threat_level={threat_level}\\n')
                  gh_output.write(f'api_calls_used={api_calls_used}\\n')
                  gh_output.write(f'cost_estimate={cost_estimate:.4f}\\n')
                  gh_output.write(f'reports_processed={reports_processed}\\n')
              
          except Exception as e:
              print(f'❌ Error processing cost data: {e}', file=sys.stderr)
              with open(os.environ['GITHUB_OUTPUT'], 'a') as gh_output:
                  gh_output.write('patriots_status=OPERATIONAL\\n')
                  gh_output.write('threat_level=LOW\\n')
                  gh_output.write('api_calls_used=0\\n')
                  gh_output.write('cost_estimate=0.0000\\n')
                  gh_output.write('reports_processed=0\\n')
          "
          else
            echo "⚠️  No data generated - activating cost-saving mode"
            echo "patriots_status=OPERATIONAL" >> $GITHUB_OUTPUT
            echo "threat_level=LOW" >> $GITHUB_OUTPUT
            echo "api_calls_used=0" >> $GITHUB_OUTPUT
            echo "cost_estimate=0.0000" >> $GITHUB_OUTPUT
            echo "reports_processed=0" >> $GITHUB_OUTPUT
          fi

      - name: Cost-Optimized Data Validation
        run: |
          echo "🔍 Validating cost-optimized data..."
          
          if [ -f ./data/news-analysis.json ]; then
            python3 -c "
          import json
          import sys
          
          try:
              with open('./data/news-analysis.json', 'r') as f:
                  data = json.load(f)
              
              # Validate cost optimization structure
              required_fields = ['articles', 'metrics', 'cost_optimization']
              missing = [f for f in required_fields if f not in data]
              
              if missing:
                  print(f'❌ Missing cost optimization fields: {missing}')
                  sys.exit(1)
              
              cost_info = data.get('cost_optimization', {})
              
              print(f'✅ Cost-optimized data validation passed')
              print(f'💰 API Efficiency: {cost_info.get(\"api_calls_used\", 0)}/{cost_info.get(\"api_calls_limit\", 8)} calls')
              print(f'📊 Data Compression: {\"Enabled\" if \"compressed\" in str(data) else \"Standard\"}')
              print(f'🔒 Security: Data retention {cost_info.get(\"data_retention_days\", 6)} days')
              
          except Exception as e:
              print(f'❌ Cost validation failed: {e}')
              sys.exit(1)
          "
          fi

      - name: Secure Backup Creation
        run: |
          echo "💾 Creating secure cost-optimized backup..."
          
          if [ -f ./data/news-analysis.json ]; then
            # Create timestamped backup
            mkdir -p backup
            cp ./data/news-analysis.json ./backup/patriots-cost-optimized-$(date +%Y%m%d-%H%M%S).json
            
            # Compress backup to save space
            gzip ./backup/patriots-cost-optimized-*.json 2>/dev/null || true
            
            # Keep only last 5 backups to save space
            ls -t ./backup/*.gz 2>/dev/null | tail -n +6 | xargs rm -f 2>/dev/null || true
            
            echo "✅ Secure backup created and old backups cleaned"
          fi

      - name: Cost-Optimized Commit
        run: |
          git config --local user.email "patriots-cost-optimized@ai.cyber"
          git config --local user.name "Patriots Protocol Cost-Optimized v4.0"
          
          # Add files
          git add data/news-analysis.json 2>/dev/null || true
          git add logs/ 2>/dev/null || true
          git add backup/ 2>/dev/null || true
          
          if git diff --staged --quiet; then
            echo "📋 No cost-optimized data changes"
          else
            # Detailed commit with cost information
            COMMIT_MSG="🎖️  Patriots Protocol v4.0: Cost-Optimized Intelligence Update"
            COMMIT_MSG="$COMMIT_MSG\n\n📅 Mission: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
            COMMIT_MSG="$COMMIT_MSG\n💰 API Calls: ${{ steps.ai_analysis.outputs.api_calls_used }}/${MAX_API_CALLS}"
            COMMIT_MSG="$COMMIT_MSG\n💰 Cost: $${{ steps.ai_analysis.outputs.cost_estimate }}"
            COMMIT_MSG="$COMMIT_MSG\n📊 Reports: ${{ steps.ai_analysis.outputs.reports_processed }}"
            COMMIT_MSG="$COMMIT_MSG\n🎯 Threat: ${{ steps.ai_analysis.outputs.threat_level }}"
            COMMIT_MSG="$COMMIT_MSG\n🔒 Retention: ${DATA_RETENTION_DAYS} days"
            COMMIT_MSG="$COMMIT_MSG\n\n🔗 https://github.com/danishnizmi/Patriots_Protocol"
            
            echo -e "$COMMIT_MSG" > commit_message.txt
            git commit -F commit_message.txt
            git push
            echo "✅ Cost-optimized data committed"
          fi

  # Optimized deployment
  deploy-cost-optimized:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    needs: cost-optimized-intelligence
    if: needs.cost-optimized-intelligence.result == 'success'
    steps:
      - name: Checkout Patriots Protocol
        uses: actions/checkout@v4
        with:
          ref: main

      - name: Setup Pages
        uses: actions/configure-pages@v5

      - name: Cost-Optimized Validation
        run: |
          echo "🌐 Validating cost-optimized deployment..."
          
          # Validate core files
          if [ -f "index.html" ] && [ -f "data/news-analysis.json" ]; then
            echo "✅ Core files validated"
            
            # Check data size for cost optimization
            DATA_SIZE=$(du -k data/news-analysis.json | cut -f1)
            echo "📊 Data size: ${DATA_SIZE}KB"
            
            if [ $DATA_SIZE -gt 100 ]; then
              echo "⚠️  Large data file detected - consider compression"
            fi
            
          else
            echo "❌ Missing core files"
            exit 1
          fi

      - name: Upload Cost-Optimized Artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: '.'

      - name: Deploy Cost-Optimized Site
        id: deployment
        uses: actions/deploy-pages@v4

      - name: Deployment Success Report
        run: |
          echo "🎖️  ═══════════════════════════════════════════════════════════════════"
          echo "     PATRIOTS PROTOCOL v4.0 - COST-OPTIMIZED DEPLOYMENT SUCCESS"
          echo "  ═══════════════════════════════════════════════════════════════════"
          echo "  🌐 URL: ${{ steps.deployment.outputs.page_url }}"
          echo "  💰 API Calls: ${{ needs.cost-optimized-intelligence.outputs.api_calls_used }}"
          echo "  💰 Cost: $${{ needs.cost-optimized-intelligence.outputs.cost_estimate }}"
          echo "  📊 Reports: ${{ needs.cost-optimized-intelligence.outputs.reports_processed }}"
          echo "  🎯 Threat: ${{ needs.cost-optimized-intelligence.outputs.threat_level }}"
          echo "  🔒 Security: Enhanced with data retention"
          echo "  ═══════════════════════════════════════════════════════════════════"

  # Cost monitoring and alerts
  cost-monitoring:
    runs-on: ubuntu-latest
    needs: [cost-optimized-intelligence]
    if: always()
    steps:
      - name: Cost Analysis Report
        run: |
          echo "🎖️  ═══════════════════════════════════════════════════════════════════"
          echo "       PATRIOTS PROTOCOL v4.0 - COST MONITORING REPORT"
          echo "  ═══════════════════════════════════════════════════════════════════"
          echo "  📅 Analysis Time: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
          echo "  💰 API Calls Used: ${{ needs.cost-optimized-intelligence.outputs.api_calls_used || '0' }}"
          echo "  💰 Estimated Cost: $${{ needs.cost-optimized-intelligence.outputs.cost_estimate || '0.0000' }}"
          echo "  💰 Cost Limit: $${COST_LIMIT_USD}"
          echo "  📊 Reports Generated: ${{ needs.cost-optimized-intelligence.outputs.reports_processed || '0' }}"
          echo "  🎯 Threat Level: ${{ needs.cost-optimized-intelligence.outputs.threat_level || 'LOW' }}"
          echo "  ⚡ Status: ${{ needs.cost-optimized-intelligence.outputs.patriots_status || 'OPERATIONAL' }}"
          echo "  🔒 Data Retention: ${DATA_RETENTION_DAYS} days"
          echo "  ═══════════════════════════════════════════════════════════════════"
          
          # Check if cost is within limits
          COST="${{ needs.cost-optimized-intelligence.outputs.cost_estimate || '0.0000' }}"
          if (( $(echo "$COST > $COST_LIMIT_USD" | bc -l) )); then
            echo "⚠️  WARNING: Cost limit exceeded!"
            echo "Consider reducing MAX_API_CALLS or increasing COST_LIMIT_USD"
          else
            echo "✅ Cost within acceptable limits"
          fi
          
          echo "Patriots Protocol v4.0 Cost-Optimized Mission Complete."
